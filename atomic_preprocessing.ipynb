{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from visual_genome import api as vg\n",
    "import multiprocessing as mp\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import csv\n",
    "import spacy\n",
    "import json\n",
    "import ijson\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atomic_df():\n",
    "    df = pd.read_csv('v4_atomic_all_agg.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Events:\n",
    "      - All events start with \"PersonX\n",
    "      - All events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant small functions\n",
    "def get_number_of_entities(event):\n",
    "    if \"PersonX\" in event and \"PersonY\" in event and \"PersonZ\" in event:\n",
    "        return 3\n",
    "    if \"PersonX\" in event and \"PersonY\" in event:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def get(verb):\n",
    "    output = []\n",
    "    cnt = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if verb in row[\"event\"]:\n",
    "            output.append(row)\n",
    "    return output\n",
    "# get(\"umbrella\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e08ee83d7d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id_vs_file_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./modelfiles/data_maps/relations_id_vs_file_map.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_relations_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_previous_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Extract relations from json for VISUAL GENOME\n",
    "def get_relation_from_relation_dict(relation):\n",
    "    relation_str = \"\"\n",
    "    \n",
    "    #########Extract Subject#########\n",
    "    if \"name\" in relation['subject']:\n",
    "        relation_str += relation['subject']['name']\n",
    "        \n",
    "    elif \"names\" in relation['subject']:\n",
    "        if len(relation['subject']['names']) == 1:\n",
    "            relation_str += str(relation['subject']['names'][0])\n",
    "        else:\n",
    "            relation_str += \" \".join(relation['subject']['names'])\n",
    "    else:\n",
    "        relation_str += str(relation['subject'])\n",
    "    \n",
    "    #########Extract Predicate#########\n",
    "    relation_str += \" \" + str(relation[\"predicate\"]) + \" \"\n",
    "    \n",
    "    #########Extract Object#########\n",
    "    if \"name\" in relation['object']:\n",
    "        relation_str +=  relation['object']['name']\n",
    "    elif \"names\" in relation['object']:\n",
    "        if len(relation['object']['names']) == 1:\n",
    "            relation_str += str(relation['object']['names'][0])\n",
    "        else:\n",
    "            relation_str +=  \" \".join(relation['object']['names'])\n",
    "    else:\n",
    "        relation_str += str(relation['oject'])\n",
    "    \n",
    "    #########process#########\n",
    "    relation_str = relation_str.lower()\n",
    "    return relation_str\n",
    "    \n",
    "def create_relations_dict(df, images_per_json_file = 1000, clear_previous_dicts = True):\n",
    "    file = open(\"./Data/relationships.json\")\n",
    "    relations = ijson.items(file, \"item\")\n",
    "\n",
    "    if not os.path.exists(\"modelfiles\"):\n",
    "        os.mkdir(\"modelfiles\")\n",
    "        \n",
    "    if not os.path.exists(\"./modelfiles/relations_dct\"):\n",
    "        os.mkdir(\"./modelfiles/relations_dct\")\n",
    "    \n",
    "    if not os.path.exists(\"./modelfiles/data_maps/\"):\n",
    "        os.mkdir(\"./modelfiles/data_maps\")\n",
    "    \n",
    "    if clear_previous_dicts == True:\n",
    "        os.system(\"rm -rf modelfiles/relations_dct/*\")\n",
    "    \n",
    "    relations_dct = {}\n",
    "    image_id_vs_file_map = {}\n",
    "    cnt = 0\n",
    "    \n",
    "    for relation in relations:\n",
    "        cnt += 1\n",
    "        if cnt % images_per_json_file == 0:\n",
    "            sys.stdout.write(\"Completed extracting relations from \" + str(cnt) + \" images\\r\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            json.dump(relations_dct, open(\"./modelfiles/relations_dct/\" + str(cnt/images_per_json_file) + \".json\" , \"w\"))\n",
    "            \n",
    "            for image_id in relations_dct.keys():\n",
    "                image_id_vs_file_map[image_id] = \"./modelfiles/relations_dct/\" + str(cnt/images_per_json_file) + \".json\"\n",
    "                \n",
    "            del relations_dct\n",
    "            relations_dct = {}\n",
    "    \n",
    "        relation_list = []\n",
    "        for r in relation[\"relationships\"]:\n",
    "            relation_list.append(get_relation_from_relation_dict(r))\n",
    "        \n",
    "        relations_dct[relation[\"image_id\"]] = {}\n",
    "        relations_dct[relation[\"image_id\"]][\"relations\"] = relation_list\n",
    "        vg.get_QA_of_image(id=61512)\n",
    "        a=vg.get_QA_of_image(id=int(relation[\"image_id\"]))\n",
    "#         relations_dct[relation[\"image_id\"]][\"qa\"] = \n",
    "        \n",
    "    json.dump(image_id_vs_file_map, open(\"./modelfiles/data_maps/relations_id_vs_file_map.json\", \"w\"))\n",
    "\n",
    "a = create_relations_dict(df, 1000, clear_previous_dicts=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Overlap between relations from VG and events from ATOMIC###########\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "def create_df_dict_by_events(df):\n",
    "    df_dct = {}\n",
    "    for index, row in df.iterrows():\n",
    "        df_dct[row[\"event\"]] = row\n",
    "    return df_dct\n",
    "\n",
    "def get_image_ids_by_overlap_relations_vs_events_singleFile(df_dct, relations_json_file, saveFile):\n",
    "    file = open(relations_json_file)\n",
    "    relations = ijson.items(file, \"item\")\n",
    "    image_relation_map = {}\n",
    "    \n",
    "    cnt = 1\n",
    "    for image_id in relations:\n",
    "        relation_words = set(\" \".join(relations[image_id]).split())\n",
    "        cnt += 1\n",
    "        \n",
    "        if cnt % 10 == 0:\n",
    "            print(relations_json_file + \": Done with \" + cnt + \" images\\r\")\n",
    "            sys.stdout.write(relations_json_file + \": Done with \" + cnt + \" images\\r\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "            \n",
    "        for event in df_dct.keys():\n",
    "            event_words = event.replace(\"PersonX\", \"\")\n",
    "            event_words = event_words.replace(\"PersonY\", \"\")\n",
    "            event_words = event_words.replace(\"PersonZ\", \"\")\n",
    "            \n",
    "            event_words = set([\"man\", \"woman\", \"person\", \"people\", \"girl\", \"boy\", \"child\", \"baby\" ].extend(event_words.split()))\n",
    "\n",
    "            intersection = event_words.intersection(relation_words)\n",
    "            \n",
    "            if len(intersection) >= THRESHOLD * len(event_words):                \n",
    "                image = vg.get_image_data(id=image_id)\n",
    "                \n",
    "                image_relation_map[event] = {\n",
    "                                                \"event_effect\": df_dct[event],\n",
    "                                                \"image_id\": image_id,\n",
    "                                                \"image_url\": image.url,\n",
    "                                                \"relations\": relations[image_id],                        \n",
    "                                            }\n",
    "    json.dump(image_relation_map, open(saveFile, \"w\"))\n",
    "    \n",
    "def get_image_ids_by_overlap_relations_vs_events(df, dir = \"./modelfiles/relations_dct/\", saveDir = \"./modelfiles/images_by_relation/\"):\n",
    "    df_dct = create_df_dict_by_events(df)\n",
    "    \n",
    "    if not os.path.exists(saveDir):\n",
    "        os.mkdir(saveDir)\n",
    "        \n",
    "    if not saveDir.endswith(\"/\"):\n",
    "        saveDir += \"/\"\n",
    "    \n",
    "    if not dir.endswith(\"/\"):\n",
    "        dir += \"/\"\n",
    "    \n",
    "    pool = mp.Pool()\n",
    "    jobs = []\n",
    "    \n",
    "    for file in os.listdir(dir):\n",
    "        job = pool.apply_async(get_image_ids_by_overlap_relations_vs_events_singleFile, (df_dct, dir + file, saveDir + file,))\n",
    "        jobs.append(job)\n",
    "        \n",
    "    for job in jobs:\n",
    "        job.get()\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "        \n",
    "# get_image_ids_by_overlap_relations_vs_events(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Two boys have made a goal out of two jackets in order to play soccer .', b'Two boys are kicking a ball to each other in the park .', b'Boys kicking soccer ball in the grass under a tree', b'Two boys kick around a ball in a meadow .', b'Two kids play soccer in a field .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3d024491837c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap_dct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"over_image_event.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mget_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-3d024491837c>\u001b[0m in \u001b[0;36mget_overlap\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_descriptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_descriptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_descriptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moverlap_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPENN/CIS700/Project/CIS700/utils.py\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(descriptions, event)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdescriptions_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mevent_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moverlap\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPENN/CIS700/Project/CIS700/utils.py\u001b[0m in \u001b[0;36mget_verbs\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnouns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PersonX'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'he'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VB'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'be'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "###########FLICKR30k Images###########\n",
    "def get_image_description_dct():\n",
    "    img_decriptions = np.genfromtxt(\"./Data/flickr30k_images/results.csv\", delimiter=\"| \", dtype=\"|S80\", skip_header=1)\n",
    "    descriptions_dct = {}\n",
    "    \n",
    "    for line in img_decriptions:\n",
    "        image_id = line[0]\n",
    "        \n",
    "        try:\n",
    "            descriptions_dct[image_id]\n",
    "        except:\n",
    "            descriptions_dct[image_id] = []\n",
    "        \n",
    "        descriptions_dct[image_id].append(line[2])\n",
    "        \n",
    "    return descriptions_dct\n",
    "\n",
    "def get_overlap():\n",
    "    df = load_atomic_df()\n",
    "    df_dct = create_df_dict_by_events(df)\n",
    "    image_descriptions = get_image_description_dct()\n",
    "    overlap_dct = {}\n",
    "    for event in df_dct:\n",
    "        for image_id in image_descriptions:\n",
    "            print(image_descriptions[image_id])\n",
    "            overlap = compare(image_descriptions[image_id], event)\n",
    "            overlap_dct[(event, image_id)] = overlap\n",
    "    \n",
    "    pickle.dump(overlap_dct, open(\"over_image_event.pkl\", \"w\"))\n",
    "    \n",
    "get_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 23, coco_id: -1, flickr_id: -1, width: 800, url: https://cs.stanford.edu/people/rak248/VG_100K/23.jpg\n"
     ]
    }
   ],
   "source": [
    "from visual_genome import api\n",
    "image = vg.get_image_data(id=23)\n",
    "print ( image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
